{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83103902",
   "metadata": {},
   "source": [
    "Use Elastic Eland & Elasticsearch-DSL python libraries and IBM Qiskit\n",
    "\n",
    "Runs on a real quantum computer\n",
    "\n",
    "Runs both Qiskit's qSVM & Scikit's classical SVM with data accessed via Eland \n",
    "\n",
    "Eland and Dataframes do not have a SVM yet\n",
    "\n",
    "Classifying nyc-restaurants dataset sitting on Elasticsearch in a qSVM running on Qiskit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f149cd",
   "metadata": {},
   "source": [
    "An example of a classification problem that requires a feature map for which computing the kernel is not efficient classically.\n",
    "\n",
    "This means that the required computational resources are expected to scale exponentially with the size of the problem.\n",
    "\n",
    "We show how this can be solved in a quantum processor by direct estimation of the kernel in the feature space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b44a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919a3110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"regular\" qiskit tools\n",
    "from qiskit import BasicAer\n",
    "from qiskit import IBMQ\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137c40cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#special svm tools\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from qiskit_machine_learning.kernels import QuantumKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2df713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import normalized_mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b05f60d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eland as ed\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import A  #aggregation\n",
    "from elasticsearch_dsl import Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a739f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Elastic Clould ID and password\n",
    "#for connecting to Elasticsearch Cloud\n",
    "with open(\"elastic_cloud_password.txt\") as f:\n",
    "          ELASTIC_CLOUD_PSSWD = f.read()\n",
    "with open(\"elastic_cloud_id.txt\") as g: ELASTIC_CLOUD_ID = g.read()\n",
    "#Connect to an Elastic Cloud Instance\n",
    "es = Elasticsearch(cloud_id=ELASTIC_CLOUD_ID,\n",
    "                   http_auth=(\"elastic\",ELASTIC_CLOUD_PSSWD),\n",
    "                   sniff_on_start=True,\n",
    "                   sniff_on_connection_fail=True,\n",
    "                   sniffer_timeout=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c8371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for pretty_printing JSON\n",
    "def json_pretty(x):\n",
    "    import json\n",
    "    print(json.dumps(x, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e13c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#little blurb for Jupyter Notebook to fill width of the browser\n",
    "#from IPython.core.display import  display, HTML\n",
    "from IPython.display import  display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ee4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###some cat commands on Elasticsaerch\n",
    "#https://elasticsearch-py.readthedocs.io/en/v7.16.2/api.html#elasticsearch\n",
    "#es.cat.nodes(h=\"name\").split(\"\\n\")\n",
    "#es.cat.indices(v=True).split(\"\\n\")\n",
    "#es.cat.indices(s=\"index\",h=\"index\").split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ed3362",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#es.search(index=\"nyc_restaurants\")\n",
    "es.count(index=\"nyc_restaurants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590c1853",
   "metadata": {},
   "source": [
    "My own dataset is  nyc_restaurants.  \n",
    "\n",
    "Probably came from the link here: https://github.com/elastic/examples/tree/master/Exploring%20Public%20Datasets/nyc_restaurants \n",
    "\n",
    "Classify nyc_restaurants by the \"grade\" fields (A,B,C,P,G,N,Z)\n",
    "\n",
    "Need to munge nyc_restaurants data to look like the \"ad_hoc\" dataset that was used by the qiskit example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d7c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#terms aggregation defined\n",
    "terms_agg = A('terms', field='grade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0199dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search that applies the terms agg, a\n",
    "#s = Search().params(size=0).aggs.bucket('grade_terms',a)\n",
    "s = Search(using=es,index='nyc_restaurants').params(size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c31a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an aggregation to the search.  Agg the field 'grade_terms' into buckets.\n",
    "s.aggs.bucket('grade_terms', terms_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b870d8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = s.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1636a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d354e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the grades?\n",
    "json_pretty(response.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb1b564",
   "metadata": {},
   "source": [
    "So the possible grades are A,B,C,P,Z,N,G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed44b228",
   "metadata": {},
   "source": [
    "Elasticsearch references\n",
    "https://elasticsearch-dsl.readthedocs.io/en/latest/search_dsl.html\n",
    "https://www.programcreek.com/python/example/117133/elasticsearch_dsl.A\n",
    "https://kb.objectrocket.com/elasticsearch/how-to-use-the-search-api-for-the-python-elasticsearch-client-265"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5715f5",
   "metadata": {},
   "source": [
    "Need to get our training and testing datasets ready.  After that we can set up the QuantumKernel class to calculate a kernel matrix using the ZZFeatureMap and use the BasicAer qasm_simulator using 1024 shots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ed9f40",
   "metadata": {},
   "source": [
    "The scikit-learn svc algorithm allows us to define a custom kernel in two ways: by providing the kernel as a callable function or by precomputing the kernel matrix. We can do either of these using the QuantumKernel class in qiskit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04288535",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -XGET \"https://705e35228a67459698fbdf4618a84821.us-central1.gcp.cloud.es.io:9243/nyc_restaurants/_search?pretty\" -u elastic:{ELASTIC_CLOUD_PSSWD}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6834671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many fields?\n",
    "!curl -s -XGET \"https://705e35228a67459698fbdf4618a84821.us-central1.gcp.cloud.es.io:9243/nyc_restaurants/_mapping?pretty\" -u elastic:{ELASTIC_CLOUD_PSSWD} | grep type | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf1b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ZZFeatureMap is the function that projects the data into additional dimensions\n",
    "## https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html\n",
    "nyc_feature_map = ZZFeatureMap(feature_dimension=2, reps=2, entanglement=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2951dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 12345\n",
    "algorithm_globals.random_seed = seed\n",
    "#print(algorithm_globals.random_seed)\n",
    "nyc_backend = QuantumInstance(BasicAer.get_backend(\"qasm_simulator\"), shots=1024, seed_simulator=seed, seed_transpiler=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a5f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1aa766",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(algorithm_globals.random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995d3e0e",
   "metadata": {},
   "source": [
    "<Data prep:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84a51fa",
   "metadata": {},
   "source": [
    "train_features in the qiskit sample adhoc dataset are pairs of floats in a list (a list of 40 lists).\n",
    "I see in nyc there are pairs of floats used for the \"location\" field. that'll do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba632058",
   "metadata": {},
   "source": [
    "By searching Elasticsearch and bringing back _source and using filter_path to get to the location field I'll have a json of \"location\": \\[ float1 float2 ]\n",
    "\n",
    "Maybe from there i can read that into a python list with json library or something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c00c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "jpairs=es.search(index='nyc_restaurants',filter_path=['hits.hits._source.location'],size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963efe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "jcount=es.count(index='nyc_restaurants')\n",
    "print(jcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8152e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=-1\n",
    "training_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ce1271",
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in jpairs['hits']['hits']:\n",
    "    i=i+1\n",
    "    w = [float(x) for x in jpairs['hits']['hits'][i]['_source']['location'].split(',')]\n",
    "    training_features.append(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e7c0af",
   "metadata": {},
   "source": [
    "ok, el is a lsit of list. each list is a pair of floats, just like train_features in adhoc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f1ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e924d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadc424",
   "metadata": {},
   "source": [
    "train labels is a simpler vector of each entry. no commas. integers. since i forced el to be \n",
    "100 entries . the values are the 'grade' field value. so need to search for grade and do same thing.\n",
    "the grades are letters. probably need to convert to numbers. o\n",
    "i don't see any \"D\" or \"F\" in the list of 100\n",
    "just found a \"P\"....  and \"Z\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1355085f",
   "metadata": {},
   "source": [
    "realizing later that the train labels are the matching labels for the train_features - duh. so need the same amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b44d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_pairs=es.search(index='nyc_restaurants',filter_path=['hits.hits._source.grade'],size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa22b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_pretty(tl_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417eeada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(_2d_list):\n",
    "    flat_list = []\n",
    "    # Iterate through the outer list\n",
    "    for element in _2d_list:\n",
    "        if type(element) is list:\n",
    "            # If the element is of type list, iterate through the sublist\n",
    "            for item in element:\n",
    "                flat_list.append(item)\n",
    "        else:\n",
    "            flat_list.append(element)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7637838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=-1\n",
    "el2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189c4e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in tl_pairs['hits']['hits']:\n",
    "    i=i+1\n",
    "    w = [''.join(ele) for ele in tl_pairs['hits']['hits'][i]['_source']['grade']]\n",
    "    el2.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e904f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "possibleGrades = ['A','B','C','P','Z','N','G']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db05ba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25040a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1521b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "el_2 = flatten_list(el2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acebaef5",
   "metadata": {},
   "source": [
    "\\\\> end of data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d68755",
   "metadata": {},
   "source": [
    "follow https://scikit-learn.org/stable/modules/preprocessing_targets.html#preprocessing-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5d4b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attempt=le.fit(possibleGrades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b690ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21271221",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels=le.transform(el_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e09ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56330c2",
   "metadata": {},
   "source": [
    "so training_labels can act as a good train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2923e1",
   "metadata": {},
   "source": [
    "next is test_features\n",
    "It is just like train_features, just a different bunch of samples. maybe just 40. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b97599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'll use \"from & size\" to grab a different bunch\n",
    "tpairs=es.search(index='nyc_restaurants',filter_path=['hits.hits._source.location'],size=40,from_=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b279eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=-1\n",
    "test_features=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7714573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in tpairs['hits']['hits']:\n",
    "    i=i+1\n",
    "    w = [float(x) for x in tpairs['hits']['hits'][i]['_source']['location'].split(',')]\n",
    "    test_features.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e43f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3065b9a5",
   "metadata": {},
   "source": [
    "test_features is a list of 40 lists and can act as our test features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9cde1c",
   "metadata": {},
   "source": [
    "Next is test_labels\n",
    "very much like train_labels, just a different bunch. el4/test features is  40 . so need 40 test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec31f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs=es.search(index='nyc_restaurants',filter_path=['hits.hits._source.grade'],size=40,from_=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ecb047",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=-1\n",
    "el6=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6389ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in test_pairs['hits']['hits']:\n",
    "    i=i+1\n",
    "    w = [''.join(ele) for ele in test_pairs['hits']['hits'][i]['_source']['grade']]\n",
    "    el6.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504053a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "el7 = flatten_list(el6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c054b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels=le.transform(el7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36916c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6de21e5",
   "metadata": {},
   "source": [
    "test_labels is my test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5643ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "IBMQ.load_account()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5e339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IBMQ.providers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1509bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = IBMQ.get_provider('ibm-q')\n",
    "provider.backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0612a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to run on a real quantum computer...\n",
    "from qiskit.providers.ibmq import least_busy\n",
    "#... find the least busy backend q machines\n",
    "device = least_busy(provider.backends(filters=lambda x: x.configuration().n_qubits >= 3 and \n",
    "                                   not x.configuration().simulator and x.status().operational==True))\n",
    "print(\"If I use a real quantum computer, going to run on current least busy device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2288e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_backend2 = QuantumInstance(backend=device, shots=1024, seed_simulator=seed, seed_transpiler=seed)\n",
    "#job = execute(grover_circuit, backend=device, shots=1024, optimization_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b51f5c4",
   "metadata": {},
   "source": [
    "The scikit-learn svc algorithm allows us to define a custom kernel in two ways: by providing the kernel as a callable function or by precomputing the kernel matrix. We can do either of these using the QuantumKernel class in qiskit.\n",
    "\n",
    "The following code gives the kernel as a callable function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0044ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nyc_backend is a simulator while nyc_backend2 is a real quantum computer\n",
    "nyc_kernel = QuantumKernel(feature_map=nyc_feature_map, quantum_instance=nyc_backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aa2981",
   "metadata": {},
   "source": [
    "Draw the circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9d17e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(training_features[0:0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a499614",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f609c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(training_features[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b128b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[item for item in training_features[0:20] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47684e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zz_circuit = nyc_kernel.construct_circuit(training_features[0],training_features[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a01e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz_circuit.decompose().decompose().decompose().draw(output='mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75116884",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(nyc_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cecd9f6",
   "metadata": {},
   "source": [
    "This code below  completes with 500 training samples and 40 test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f0f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_svc = SVC(kernel=nyc_kernel.evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3769ffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_svc.fit(training_features, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d451284",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_score = nyc_svc.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54016139",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Callable kernel classification test score: {nyc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec4695",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf8125e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Callable kernel classification test score: 1.0\n",
    "#The following code precomputes and plots the training and testing kernel matrices before providing them to the scikit-learn svc algorithm:\n",
    "\n",
    "nyc_matrix_train = nyc_kernel.evaluate(x_vec=training_features)\n",
    "nyc_matrix_test = nyc_kernel.evaluate(x_vec=test_features, y_vec=training_features)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(\n",
    "    np.asmatrix(nyc_matrix_train), interpolation=\"nearest\", origin=\"upper\", cmap=\"Blues\"\n",
    ")\n",
    "axs[0].set_title(\"NYC_Restaurant training kernel matrix\")\n",
    "axs[1].imshow(np.asmatrix(nyc_matrix_test), interpolation=\"nearest\", origin=\"upper\", cmap=\"Reds\")\n",
    "axs[1].set_title(\"NYC_Restaurant testing kernel matrix\")\n",
    "plt.show()\n",
    "\n",
    "nyc_svc = SVC(kernel=\"precomputed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65703fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_svc.fit(nyc_matrix_train, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731831e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_score = nyc_svc.score(nyc_matrix_test, test_labels)\n",
    "print(f\"Precomputed kernel classification test score: {nyc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a5c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qsvc = QSVC(quantum_kernel=nyc_kernel)\n",
    "qsvc.fit(training_features, training_labels)\n",
    "qsvc_score = qsvc.score(test_features, test_labels)\n",
    "\n",
    "print(f\"QSVC classification test score: {qsvc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ce3f1a",
   "metadata": {},
   "source": [
    "This is supervised learning where the kernel is calculated in the training phase and the support vectors obtained and again in a test or classification phase where new unlabeled data is classified according to the solution found in the training phase."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
